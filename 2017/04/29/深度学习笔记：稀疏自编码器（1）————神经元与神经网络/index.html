<!DOCTYPE html>
<!--[if IE 8]> <html lang="en" class="ie8 no-js"> <![endif]-->
<!--[if IE 9]> <html lang="en" class="ie9 no-js"> <![endif]-->
<!--[if !IE]><!-->
<html lang="en">
<!--<![endif]-->
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <title>深度学习笔记：稀疏自编码器（1）——神经元与神经网络 | Aaron Wu</title>

  <meta content="width=device-width, initial-scale=1.0" name="viewport">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">

  <meta name="description" content="笔者在很久以前就已经学习过UFLDL深度学习教程中的稀疏自编码器，近期需要用到的时候发现有些遗忘，温习了一遍之后决定在这里做一下笔记。">
<meta property="og:type" content="article">
<meta property="og:title" content="深度学习笔记：稀疏自编码器（1）——神经元与神经网络">
<meta property="og:url" content="https://wanz2.github.io/2017/04/29/深度学习笔记：稀疏自编码器（1）————神经元与神经网络/index.html">
<meta property="og:site_name" content="Aaron Wu">
<meta property="og:description" content="笔者在很久以前就已经学习过UFLDL深度学习教程中的稀疏自编码器，近期需要用到的时候发现有些遗忘，温习了一遍之后决定在这里做一下笔记。">
<meta property="og:image" content="http://odnk9as2f.bkt.clouddn.com/300px-SingleNeuron.png">
<meta property="og:image" content="http://odnk9as2f.bkt.clouddn.com/400px-Network331.png">
<meta property="og:updated_time" content="2017-05-16T16:26:01.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="深度学习笔记：稀疏自编码器（1）——神经元与神经网络">
<meta name="twitter:description" content="笔者在很久以前就已经学习过UFLDL深度学习教程中的稀疏自编码器，近期需要用到的时候发现有些遗忘，温习了一遍之后决定在这里做一下笔记。">
<meta name="twitter:image" content="http://odnk9as2f.bkt.clouddn.com/300px-SingleNeuron.png">
  
    <link rel="alternative" href="/atom.xml" title="Aaron Wu" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.ico">
  
    
  <meta content="{{ title }}" name="description">
  <meta content="{{ title }}" name="keywords">
  <meta content="{{ title }}" name="author">

  <link href="http://fonts.googleapis.com/css?family=Open+Sans:300,400,600,700|PT+Sans+Narrow|Source+Sans+Pro:200,300,400,600,700,900&amp;subset=all" rel="stylesheet" type="text/css">

  <!-- Global styles START -->   
  <link rel="stylesheet" href="/metronic/assets/plugins/font-awesome/css/font-awesome.min.css">
  <link rel="stylesheet" href="/metronic/assets/plugins/bootstrap/css/bootstrap.min.css">
  <!-- Global styles END --> 
   
  <!-- Page level plugin styles START -->
  <link rel="stylesheet" href="/metronic/assets/pages/css/animate.css">
  <link rel="stylesheet" href="/metronic/assets/plugins/owl.carousel/assets/owl.carousel.css">
  <!-- Page level plugin styles END -->

  <!-- Theme styles START -->
  <link rel="stylesheet" href="/metronic/assets/pages/css/components.css">
  <link rel="stylesheet" href="/metronic/assets/pages/css/slider.css">
  <link rel="stylesheet" href="/metronic/assets/corporate/css/style.css">
  <link rel="stylesheet" href="/metronic/assets/pages/css/portfolio.css">
  <link rel="stylesheet" href="/metronic/assets/corporate/css/style-responsive.css">
  <link rel="stylesheet" href="/metronic/assets/corporate/css/themes/red.css">
  <link rel="stylesheet" href="/css/theme-styles.css">
  <!-- Theme styles END --><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>

<body class="corporate">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><!-- BEGIN TOP BAR -->
<div class="pre-header">
  <div class="container">
    <div class="row">
      <!-- BEGIN TOP BAR LEFT PART -->
      <div class="col-md-6 col-sm-6 col-xs-9 additional-shop-info">
	<ul class="list-unstyled list-inline">
	  <li><i class="fa fa-phone"></i><span>716-472-4484</span></li>
	  <li><i class="fa fa-envelope-o"></i><span>ptsteadman@gmail.com</span></li>
	</ul>
      </div>
      <!-- END TOP BAR LEFT PART -->
      <!-- BEGIN TOP BAR MENU -->
      <div class="col-md-6 col-sm-6 col-xs-3 additional-nav">
	<ul class="list-unstyled list-inline pull-right">
	  <li><a href="/login">Log In</a></li>
	</ul>
      </div>
      <!-- END TOP BAR MENU -->
    </div>
  </div>        
</div>
<!-- END TOP BAR -->
<!-- BEGIN HEADER -->
<div class="header">
  <div class="container">
    <!--<a class="site-logo" href="/" id="logo">Aaron Wu</a>-->

    <a class="site-logo" href="/">
      <img src="/metronic/assets/corporate/img/logos/logo-corp-red.png" alt="Metronic FrontEnd">
    </a>

    <a href="javascript:void(0);" class="mobi-toggler"><i class="fa fa-bars"></i></a>

    <!-- BEGIN NAVIGATION -->
    <div class="header-navigation pull-right font-transform-inherit">
      <ul>
	
	<li class="">
	  <a  href="/">Home</a>
	</li>
	
	<li class="">
	  <a  href="/projects/">Projects</a>
	</li>
	
	<li class="">
	  <a  href="/archives/">Blog</a>
	</li>
	
	<li class="">
	  <a  href="/contact/">Contact</a>
	</li>
	
	<li class="">
	  <a  href="/about/">About</a>
	</li>
	
	<!-- BEGIN TOP SEARCH -->
	<li class="menu-search">
	  <span class="sep"></span>
	  <i class="fa fa-search search-btn"></i>
	  <div class="search-box">
	    <form action="#">
	      <div class="input-group">
		<input type="text" placeholder="Search" class="form-control st-default-search-input">
		<span class="input-group-btn">
		  <button class="btn btn-primary" type="submit">Search</button>
		</span>
	      </div>
	    </form>
	  </div> 
	</li>
	<!-- END TOP SEARCH -->
      </ul>
    </div>
    <!-- END NAVIGATION -->
  </div>
</div>
<!-- Header END -->

  <div class="container">
  <ul class="breadcrumb">
    <li><a href="/">Home</a></li>
    <li><a href="/archives/">Blog</a></li>
    <li class="active">Post</li>
  </ul>
  <section id="main">
    
    <h2 itemprop="name">
      <a class="article-title" href="/2017/04/29/深度学习笔记：稀疏自编码器（1）————神经元与神经网络/">深度学习笔记：稀疏自编码器（1）——神经元与神经网络</a>
    </h2>


    <div class="row">
<div class="col-md-9 col-sm-9 blog-posts">
<article id="post-深度学习笔记：稀疏自编码器（1）————神经元与神经网络" class="article article-type-post blog-item" itemscope itemprop="blogPost">
  <div class="article-meta">
  </div>
  <div class="article-inner">
    
    
    <header class="article-header">
      <ul class="blog-info">
	<li><i class="fa fa-user"></i> Anonymous</li>
	<li><i class="fa fa-calendar"></i>
	  <time datetime="2017-04-29T15:38:52.000Z" itemprop="datePublished">2017/04/29</time>

	</li>
	<li class="hidden-xs"><i class="fa fa-comments"></i>
	  <a href="https://wanz2.github.io/2017/04/29/深度学习笔记：稀疏自编码器（1）————神经元与神经网络/#disqus_thread" class="article-comment-link">Comments</a>
	</li>
	<li class="hidden-xs"><i class="fa fa-tags"></i> 
	  
  
    <a href="/tags/机器学习/" title="机器学习">机器学习</a>
  


	</li>
      </ul>
      
  <div class="article-category">
    
    Category: 
    
    Categories:
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a>
  </div>
  <br>


    </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>&emsp;&emsp;笔者在很久以前就已经学习过UFLDL深度学习教程中的稀疏自编码器，近期需要用到的时候发现有些遗忘，温习了一遍之后决定在这里做一下笔记，本文不是对神经元与神经网络的介绍，而是笔者学习之后做的归纳和整理，打算分为几篇记录。详细教程请见<a href="http://deeplearning.stanford.edu/wiki/index.php/UFLDL%E6%95%99%E7%A8%8B" target="_blank" rel="external">UFLDL教程</a>，看完教程之后再来看本文可能会更加清晰。  </p>
<a id="more"></a>
<h2 id="0-本文中使用的符号一览及本文中的一些约定"><a href="#0-本文中使用的符号一览及本文中的一些约定" class="headerlink" title="0. 本文中使用的符号一览及本文中的一些约定"></a>0. 本文中使用的符号一览及本文中的一些约定</h2><table>
<thead>
<tr>
<th>符号</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>$x$</td>
<td>输入值向量，为$n$维</td>
</tr>
<tr>
<td>$x_i$</td>
<td>第$i$个输入值</td>
</tr>
<tr>
<td>$f()$</td>
<td>神经元激活函数，本文中为sigmoid函数，即$f(z)=\frac{1}{1+e^{(-z)}}$</td>
</tr>
<tr>
<td>$W_{ij}^{(l)}$</td>
<td>神经网络中第$l$层第$j$个神经元和第$l+1$层第$i$个神经元连线上的权值</td>
</tr>
<tr>
<td>$b_i^{(l)}$</td>
<td>第$l+1$层第$i$个神经元输入的偏置项</td>
</tr>
<tr>
<td>$n_l$</td>
<td>神经网络的总层数</td>
</tr>
<tr>
<td>$L_l$</td>
<td>第$l$层，则输入层为$L<em>1$，输出层为$L</em>{nl}$</td>
</tr>
<tr>
<td>$s_l$</td>
<td>第$l$层的节点数（不包括偏置单元）</td>
</tr>
<tr>
<td>$a_i^{l}$</td>
<td>第$l$层第$i$单元的激活值（输出值），当$l=1$时，$a_i^{(1)}=x_i$</td>
</tr>
<tr>
<td>$z_i^{(l)}$</td>
<td>第$l$层第$i$单元输入加权和（包括偏置单元），有$a_i^{(l)}=f(z_i^{(l)})$</td>
</tr>
<tr>
<td>$h_{W,b}(x)$</td>
<td>输入值为$x$，神经网络中权值和偏置项分别为$W,b$的情况下的输出值</td>
</tr>
</tbody>
</table>
<p>&emsp;&emsp;<strong>约定</strong> 本文中将函数$f()$以及偏导数$f’()$进行了针对向量参数的扩展，即：<br>&emsp;&emsp;$f([z_1,z_2,z_3])=[f(z_1),f(z_2),f(z_3)]$<br>&emsp;&emsp;$f’([z_1,z_2,z_3])=[f’(z_1),f’(z_2),f’(z_3)]$  </p>
<h2 id="1-神经元"><a href="#1-神经元" class="headerlink" title="1. 神经元"></a>1. 神经元</h2><h3 id="1-1-神经元定义"><a href="#1-1-神经元定义" class="headerlink" title="1.1 神经元定义"></a>1.1 神经元定义</h3><p>&emsp;&emsp;神经元是以$x$为输入，$h_{W,b}$为输出的运算单元，如图所示：    </p>
<p><img src="http://odnk9as2f.bkt.clouddn.com/300px-SingleNeuron.png" alt="神经元">  </p>
<h3 id="1-2-激活函数"><a href="#1-2-激活函数" class="headerlink" title="1.2 激活函数"></a>1.2 激活函数</h3><p>&emsp;&emsp;通常在神经元中输出值为0表示神经元被激活，输出为1表示神经元被抑制，而计算输出值所用的函数则被称为“激活函数”。本文中所用的激活函数为sigmoid函数：<br>&emsp;&emsp;&emsp;&emsp;$f(z)=\frac{1}{1+e^{(-z)}}$，其定义域为$(-\infty,+\infty)$，值域为$(0,1)$。<br>&emsp;&emsp;以上图神经元为例，假设第$i$个输入值与神经元连线上的权重为$w_1$，输入值偏置项为$b<em>1$，在单个神经元中，有：<br>&emsp;&emsp;$h</em>{W,b}(x)=f(x_1w_1+x_2w_2+x_3w_3+b_1)$<br>&emsp;&emsp;观察可以发现，单个神经元就是一个<strong>逻辑回归</strong>模型。  </p>
<h2 id="2-神经网络"><a href="#2-神经网络" class="headerlink" title="2. 神经网络"></a>2. 神经网络</h2><h3 id="2-1-神经网络定义"><a href="#2-1-神经网络定义" class="headerlink" title="2.1 神经网络定义"></a>2.1 神经网络定义</h3><p>&emsp;&emsp;神经网络就是将多个神经元连在一起，前一层神经元的输出就是后一层神经元的输入，下图是一个三层神经网络：<br><img src="http://odnk9as2f.bkt.clouddn.com/400px-Network331.png" alt="三层神经网络模型"><br>&emsp;&emsp;以上图为例，最左边一层为<strong>输入层</strong>，中间一层为<strong>隐藏层</strong>，最右边一层为<strong>输出层</strong>。  </p>
<h3 id="2-2-前向传播"><a href="#2-2-前向传播" class="headerlink" title="2.2 前向传播"></a>2.2 前向传播</h3><p>&emsp;&emsp;前向传播就是使用输入值$x$通过神经网络计算出输出值$h_{W,b}(x)$的过程。以上图神经网络为例，前向传播中每一个神经元输入输出过程如下：<br>&emsp;&emsp;令$z_i^{(l)}$表示第$l$层第$i$个神经元的输入值，有<br>&emsp;&emsp;$z<em>i^{(l+1)}=W</em>{i1}^{(l)}x<em>1+W</em>{i2}^{(l)}x<em>2+W</em>{i3}^{(l)}x_3+b_i^{(l)}$（这里其实是一个<strong>线性回归</strong>模型）<br>&emsp;&emsp;$a_i^{(l)}=f(z<em>i^{(l)})$<br>&emsp;&emsp;$h</em>{W,b}(x)=a_1^{(3)}$  </p>
<h3 id="2-3-前向传播的矩阵表示"><a href="#2-3-前向传播的矩阵表示" class="headerlink" title="2.3 前向传播的矩阵表示"></a>2.3 前向传播的矩阵表示</h3><p>&emsp;&emsp;本文中扩展了函数$f()$针对向量参数的约定，即有：<br>&emsp;&emsp;$f([z_1,z_2,z_3])=[f(z_1),f(z_2),f(z<em>3)]$<br>&emsp;&emsp;则上图神经网络中的前向传播过程可表示为：<br>&emsp;&emsp;$z^{(2)}=W^{(1)}x+b^{(1)}$<br>&emsp;&emsp;$a^{(2)}=f(z^{(2)})$<br>&emsp;&emsp;$z^{(3)}=W^{(2)}a^{(2)}+b^{(2)}$<br>&emsp;&emsp;$h</em>{W,b}(x)=f(z^{(3)})$<br>&emsp;&emsp;下面以$z^{(2)}=W^{(1)}x+b^{(1)}$为例，展开一下具体的矩阵表示，其他式子略：<br>&emsp;&emsp;<br>$\begin{pmatrix}<br>z_1^{(2)}\<br>z_2^{(2)}\<br>z<em>3^{(2)}\<br>\end{pmatrix}$<br>$=<br>\begin{pmatrix}<br>W</em>{11}^{(1)}&amp;W<em>{12}^{(1)}&amp;W</em>{13}^{(1)}\<br>W<em>{21}^{(1)}&amp;W</em>{22}^{(1)}&amp;W<em>{23}^{(1)}\<br>W</em>{31}^{(1)}&amp;W<em>{32}^{(1)}&amp;W</em>{33}^{(1)}\<br>\end{pmatrix}$<br>$\begin{pmatrix}x_1\<br>x_2\<br>x_3\<br>\end{pmatrix}$<br>$+<br>\begin{pmatrix}<br>b_1^{(1)}\<br>b_2^{(1)}\<br>b_3^{(1)}\<br>\end{pmatrix}$  </p>
<p>&emsp;&emsp;最终，神经网络前向传播过程可表示为：<br>&emsp;&emsp;$z^{(l+1)}=W^{(l)}a^{(l)}+b^{(l)}$<br>&emsp;&emsp;$a^{(l+1)}=f(z^{(l+1)})$  </p>

      
    </div>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2017/04/29/深度学习笔记：稀疏自编码器（2）——反向传导/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          深度学习笔记：稀疏自编码器（2）——反向传导
        
      </div>
    </a>
  
  
    <a href="/2017/04/06/压缩感知算法原理/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">压缩感知算法原理</div>
    </a>
  
</nav>

  
  <br>
</article>




</div>
<div class="col-md-3 col-sm-3 blog-sidebar">
  <!-- CATEGORIES START -->
<h2 class="no-top-space">Categories</h2>

<div class="widget-wrap">
  <div class="widget">
    <ul class="nav sidebar-categories margin-bottom-40">
      
	<li>
	  <a href="/categories/Java/">Java (6)</a>
	</li>
      
	<li>
	  <a href="/categories/机器学习/">机器学习 (6)</a>
	</li>
      
	<li>
	  <a href="/categories/Linux/">Linux (1)</a>
	</li>
      
	<li>
	  <a href="/categories/图像处理/">图像处理 (1)</a>
	</li>
      
    </ul>
  </div>
</div>


<!-- CATEGORIES END -->

<!-- BEGIN BLOG TAGS -->
<div class="blog-tags margin-bottom-20">
  <h2>Tags</h2>
  
  <div class="widget-wrap">
    <div class="widget">
      
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Java/"><i class='fa fa-tags'></i>Java</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Linux/"><i class='fa fa-tags'></i>Linux</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/图像处理/"><i class='fa fa-tags'></i>图像处理</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/机器学习/"><i class='fa fa-tags'></i>机器学习</a></li></ul>
    </div>
  </div>


</div>
<!-- END BLOG TAGS -->


<!-- BEGIN FEATURED POSTS -->                            
<h2>Featured Posts</h2>
<div class="recent-news margin-bottom-10">
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
</div>
<!-- END FEATURED POSTS -->                            

</div>
</div>

  </section>
</div>

    <!-- BEGIN PRE-FOOTER -->
    <div class="pre-footer">
      <div class="container">
        <div class="row">
          <!-- BEGIN BOTTOM ABOUT BLOCK -->
          <div class="col-md-4 col-sm-6 pre-footer-col">
            <h2>About Us</h2>
            <p>Computer Lab is a software development and marketing company based in Brooklyn, New York. <br><br> Computer Lab was founded in 2015, and is focused on so on and so forth.</p>
          </div>
          <!-- END BOTTOM ABOUT BLOCK -->

          <!-- BEGIN BOTTOM CONTACTS -->
          <div class="col-md-4 col-sm-6 pre-footer-col">
            <h2>Contact</h2>
            <address class="margin-bottom-40">
              140 Metropolitan Avenue<br>
              5th Floor<br>
              Brooklyn, NY 11249<br>
              Phone: 716-472-4484<br>
              Email: <a href="mailto:ptsteadman@gmail.com">ptsteadman@gmail.com</a><br>
            </address>
          </div>
          <!-- END BOTTOM CONTACTS -->

	
          <!-- BEGIN TWITTER BLOCK --> 
          <div class="col-md-4 col-sm-6 pre-footer-col">

	  <a data-tweet-limit="1" class="twitter-timeline"
	  href="https://twitter.com/computerlab_"
	  data-widget-id="678830341331820544">Tweets by @computerlab_</a>

	  <script>!function(d,s,id){var
	  js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+"://platform.twitter.com/widgets.js";fjs.parentNode.insertBefore(js,fjs);}}(document,"script","twitter-wjs");</script>

          </div>
          <!-- END TWITTER BLOCK -->
	
        </div>
      </div>
    </div>
    <!-- END PRE-FOOTER -->

    <!-- BEGIN FOOTER -->
    <div class="footer">
      <div class="container">
        <div class="row">
          <!-- BEGIN COPYRIGHT -->
          <div class="col-md-6 col-sm-6 padding-top-10">
                  &copy; 2017 Aaron Wu<br>
 <a href="javascript:;">Privacy Policy</a> | <a href="javascript:;">Terms of Service</a>
          </div>
          <!-- END COPYRIGHT -->
	  <!-- BEGIN SOCIAL -->
<div class="col-md-6 col-sm-6">
  <ul class="social-footer list-unstyled list-inline pull-right">
    
      <li><a href="https://github.com/ptsteadman"><i class="fa fa-github"></i></a></li>
    
      <li><a href="https://twitter.com/ptsteadman"><i class="fa fa-twitter"></i></a></li>
    
      <li><a href="https://www.facebook.com/ptsteadman"><i class="fa fa-facebook"></i></a></li>
    
      <li><a href="/atom.xml"><i class="fa fa-rss"></i></a></li>
    
      <li><a href="https://linkedin.com/in/ptsteadman"><i class="fa fa-linkedin"></i></a></li>
    
      <li><a href="http://stackoverflow.com/users/2480493/patrick-steadman"><i class="fa fa-stackoverflow"></i></a></li>
    
  </ul>  
</div>
<!-- END SOCIAL -->

        </div>
      </div>
    </div>
    <!-- END FOOTER -->

  <!-- BEGIN CORE PLUGINS (REQUIRED FOR ALL PAGES) -->
<!--[if lt IE 9]>
<script src="/metronic/assets/plugins/respond.min.js"></script>
<![endif]--> 
<script src="/metronic/assets/plugins/jquery.min.js"></script>
<script src="/metronic/assets/plugins/jquery-migrate.min.js"></script>
<script src="/metronic/assets/plugins/bootstrap/js/bootstrap.min.js"></script>
<script src="/metronic/assets/corporate/scripts/back-to-top.js"></script>
<script src="/metronic/assets/plugins/owl.carousel/owl.carousel.min.js"></script>
<script src="/metronic/assets/corporate/scripts/layout.js"></script>
<script src="/js/wow.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script type="text/javascript">
    jQuery(document).ready(function() {
        Layout.init();    
        Layout.initOWL();
        Layout.initTwitter();
        Layout.initFixHeaderWithPreHeader(); /* Switch On Header Fixing (only if you have pre-header) */
        Layout.initNavScrolling(); 
	new WOW().init();
    });
</script>
<!-- END CORE PLUGINS -->

<!-- BEGIN PAGE-SPECIFIC PLUGINS --> 







<!-- END PAGE-SPECIFIC PLUGINS --> 

<!-- BEGIN INTEGRATIONS -->





<!-- END INTEGRATIONS --><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->

</body>
</html>
