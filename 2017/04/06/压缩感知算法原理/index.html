<!DOCTYPE HTML>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <title>压缩感知算法原理 | Aaron Wu</title>
  <meta name="author" content="Aaron Wu">
  
  <meta name="description" content="本文是笔者在学习压缩感知算法之后的总结和整理。">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <meta property="og:title" content="压缩感知算法原理">
  <meta property="og:site_name" content="Aaron Wu">

  
    <meta property="og:image" content="undefined">
  

  
  
    <link href="/favicon.png" rel="icon">
  

  <!-- CSS -->
  <link rel="stylesheet" href="/css/themes/cerulean.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/font-awesome.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/responsive.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/highlight.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/highlight-default.min.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/google-fonts.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/comment.css" media="screen" type="text/css">
  <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
	<script src="https://cdnjs.cloudflare.com/ajax/libs/es5-shim/4.5.9/es5-shim.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/es5-shim/4.5.7/es5-sham.min.js"></script>
  <![endif]-->

  <script src="/js/jquery-2.0.3.min.js"></script>
  
    <script src="/js/marked.js"></script>
    <script src="/js/comment.js"></script>
    <script src="/js/timeago.min.js"></script>
    <script src="/js/highlight.min.js"></script>
	<script src="/js/spin.min.js"></script>
  
  <!-- analytics --><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  



</head>

<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><nav id="main-nav" class="navbar navbar-inverse navbar-default navbar-fixed-top" role="navigation">
    <div class="container">
      <button type="button" class="navbar-header navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
	<span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
       <a class="navbar-brand" href="/">Aaron Wu</a>
      <div class="collapse navbar-collapse nav-menu">
		<ul class="nav navbar-nav">
		  
		  <li>
			<a href="/archives" title="All the articles.">
			  <i class="fa fa-archive"></i>Archives
			</a>
		  </li>
		  
		  <li>
			<a href="/categories" title="All the categories.">
			  <i class="fa fa-folder"></i>Categories
			</a>
		  </li>
		  
		  <li>
			<a href="/tags" title="All the tags.">
			  <i class="fa fa-tags"></i>Tags
			</a>
		  </li>
		  
		  <li>
			<a href="/about" title="About me.">
			  <i class="fa fa-user"></i>About
			</a>
		  </li>
		  
		</ul>
      </div>
    </div> <!-- container -->
</nav>
<div class="clearfix"></div>

  <div class="container">
    <div class="content">
      


	
		<div class="page-header page-header-inverse ">		
			<h1 class="title title-inverse "> 压缩感知算法原理</h1>
		</div>		
	






<div class="row post">
	<!-- cols -->
	
	<div id="top_meta"></div>
	<div class="col-md-9">
	

	<!-- content -->
	<div class="mypage">		
	  
		 <div class="alert alert-success description">
			<i class="fa fa-info-circle"></i> <p>本文是笔者在学习压缩感知算法之后的总结和整理。</p>
			
		 </div> <!-- alert -->
	  		

	  <p>&emsp;&emsp;本文是笔者在学习压缩感知算法之后的总结和整理。  </p>
<a id="more"></a>
<h2 id="1-本文中使用的符号一览"><a href="#1-本文中使用的符号一览" class="headerlink" title="1. 本文中使用的符号一览"></a>1. 本文中使用的符号一览</h2><h3 id="传统正交变换中："><a href="#传统正交变换中：" class="headerlink" title="传统正交变换中："></a>传统正交变换中：</h3><table>
<thead>
<tr>
<th>符号</th>
<th>维度</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>$x$</td>
<td>$R^{N\times 1}$</td>
<td>原始信号</td>
</tr>
<tr>
<td>$y$</td>
<td>$R^{N\times 1}$</td>
<td>压缩后的信号，不稀疏</td>
</tr>
<tr>
<td>$\hat{y}$</td>
<td>$R^{N\times 1}$</td>
<td>由$y$中$K$个分量放在对应位置构成，其余位置为0，是$K$-稀疏的</td>
</tr>
</tbody>
</table>
<h3 id="压缩感知算法中："><a href="#压缩感知算法中：" class="headerlink" title="压缩感知算法中："></a>压缩感知算法中：</h3><table>
<thead>
<tr>
<th>符号</th>
<th>维度</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>$x$</td>
<td>$R^{N\times 1}$</td>
<td>原始信号</td>
</tr>
<tr>
<td>$y$</td>
<td>$R^{M\times 1}$</td>
<td>压缩感知的<strong>观测向量</strong>，是$x$的$M$个线性度量</td>
</tr>
<tr>
<td>$s$</td>
<td>$R^{N\times 1}$</td>
<td>信号$x$在$\Psi$域的稀疏表示，是$K$-稀疏的</td>
</tr>
<tr>
<td>$\Psi$</td>
<td>$C^{N\times N}$</td>
<td><strong>稀疏矩阵</strong>，为正交变换矩阵</td>
</tr>
<tr>
<td>$\Psi^\mathrm{H}$</td>
<td>$C^{N\times N}$</td>
<td>正交变换矩阵$\Psi$的转置矩阵</td>
</tr>
<tr>
<td>$\Phi$</td>
<td>$R^{M\times N}$</td>
<td>称为<strong>测量矩阵</strong>，有$M\ll N$</td>
</tr>
<tr>
<td>$T$</td>
<td>$R^{M\times N}$</td>
<td>$T=\Phi\Psi^\mathrm{H}$，称为<strong>传感矩阵</strong></td>
</tr>
<tr>
<td>$\delta$</td>
<td>$1\times 1$</td>
<td>一个较小的正的常数</td>
</tr>
</tbody>
</table>
<h2 id="2-压缩感知算法目的"><a href="#2-压缩感知算法目的" class="headerlink" title="2. 压缩感知算法目的"></a>2. 压缩感知算法目的</h2><p>&emsp;&emsp;压缩感知算法的目的是采集很少一部分数据，并希望从中“解压缩”出大量信息，达到恢复原信号的效果  </p>
<h2 id="3-采集策略"><a href="#3-采集策略" class="headerlink" title="3. 采集策略"></a>3. 采集策略</h2><p>&emsp;&emsp;a. 少量的采集到的数据包含了原信号的全局信息<br>&emsp;&emsp;b. 存在一种算法能够从这些少量的数据中还原出原先的信息来  </p>
<h2 id="4-传统解决思路——正交变换"><a href="#4-传统解决思路——正交变换" class="headerlink" title="4. 传统解决思路——正交变换"></a>4. 传统解决思路——正交变换</h2><h3 id="4-1-步骤"><a href="#4-1-步骤" class="headerlink" title="4.1 步骤"></a>4.1 步骤</h3><ol>
<li><p>对于原始信号$x\in R^{N\times 1}$，可以通过正交变换来进行压缩，正变换：$y=\Psi x$，反变换$x=\Psi^\mathrm{H}y$。<br>这里$\Psi$是正交矩阵，有$\Psi\Psi^\mathrm{H}=\Psi^\mathrm{H}\Psi=I$，亦即$\Psi^\mathrm{H}=\Psi^\mathrm{-1}$，$\Psi\in C^{N\times N}$，$I$是单位矩阵。  </p>
</li>
<li><p>对于$y\in C^{N\times 1}$，能量较$x$集中，本质上去除了$x$中的相关性。因此，我们只保留$K$个较大分量，而把其他$N-K$个置为零，通过反变换，我们能够近乎完美的重建原始信号 ，具有这样性质的信号被称为$K$“稀疏”的。  </p>
</li>
</ol>
<h3 id="4-2-编码解码策略"><a href="#4-2-编码解码策略" class="headerlink" title="4.2 编码解码策略"></a>4.2 编码解码策略</h3><p>&emsp;&emsp;编码：构造$\Psi $，做正变换$y=\Psi x$，保留$y$中最重要的$K$个分量和其对应位置。  </p>
<p>&emsp;&emsp;解码：把$K$个分量放回到对应位置，其他位置填上0，构造$\Psi^\mathrm{H}$，反变换$\hat{x}=\Psi^\mathrm{H} \hat{y}$。  </p>
<h3 id="4-3-压缩误差分析"><a href="#4-3-压缩误差分析" class="headerlink" title="4.3 压缩误差分析"></a>4.3 压缩误差分析</h3><p>&emsp;&emsp;显然，我们希望$\Vert x-\hat{x}\Vert _2=\Vert y-\hat{y}\Vert _2\leq \delta$，$\delta$是一个小的常数。  </p>
<p>&emsp;&emsp;但更有效的是利用<font style="color:red;">相对误差</font> $\frac{\Vert y-\hat{y}\Vert _2}{\Vert y\Vert _2}\leq\delta$。  </p>
<h2 id="5-新的思路——压缩传感"><a href="#5-新的思路——压缩传感" class="headerlink" title="5. 新的思路——压缩传感"></a>5. 新的思路——压缩传感</h2><h3 id="5-1-压缩传感思想："><a href="#5-1-压缩传感思想：" class="headerlink" title="5.1 压缩传感思想："></a>5.1 压缩传感思想：</h3><p>&emsp;&emsp;对于信号，$x\in R^{N\times 1}$，我们可以找到它的$M$个线性测量（Linear Measurement，意即降维后的信号为$M$维），$y=\Phi x，\Phi\in R^{M\times N}$。  </p>
<p>&emsp;&emsp;$\Phi$中的每一行看作一个传感器，它与信号相乘，拾取了信号的一部分信息。拥有了这$M$个测量（即$y$）和$\Phi$，我们就可以近乎完美的重构原始信号了。  </p>
<p>&emsp;&emsp;<strong>那么已知$y$和$\Phi$如何重构信号？这是一个最优化问题，根据以下式子:</strong>  </p>
  <p align="center">目标函数$min\Vert s\Vert _0$，且满足等式约束<br>      $\Phi\Psi^\mathrm{H}s=y$<br>      <br>或者可以写成<br>$min\Vert y-\Phi\Psi^\mathrm{H}s\Vert _2+\lambda\Vert s\Vert _0$</p>  

<p>可以求得$s$。<br>&emsp;&emsp;因为$\Phi\Psi^\mathrm{H}s=\Phi\hat{x}=y$，所以$\hat{x}=\Psi^\mathrm{H}s$，这里就是传统方法正交变换中用$s$恢复$x$的方法，这里的$s$是K-sparse的。    </p>
<h3 id="5-2-根据以上分析，可以得出编码解码策略"><a href="#5-2-根据以上分析，可以得出编码解码策略" class="headerlink" title="5.2 根据以上分析，可以得出编码解码策略"></a>5.2 根据以上分析，可以得出编码解码策略</h3><p>&emsp;&emsp;编码：针对原始信号$x$构造$\Phi$，生成测量$y=\Phi x$，保留$y$。  </p>
<p>&emsp;&emsp;解码：构造同样的$\Phi$，构造<font style="color:red">任一种正交变换$\Psi^\mathrm{H}$</font>，根据$y$重构$x$。  </p>
<hr>
<p>&emsp;&emsp;到这里，我们已经知道通过$y$恢复$x$的大致步骤，那么具体怎样操作呢？有这样三个关键问题： </p>
<p>&emsp;&emsp;(1) 观测矩阵$\Phi$的选择需要满足什么性质？  </p>
<p>&emsp;&emsp;(2) 如何最优化本文4.1中 $min\Vert y-\Phi\Psi^\mathrm{H}s\Vert _2+\lambda\Vert s\Vert _0$ 这个函数以求出$s$呢？  </p>
<p>&emsp;&emsp;下文将针对上述两个问题进行分析。  </p>
<hr>
<h3 id="5-3-观测矩阵-Phi-需要满足的性质"><a href="#5-3-观测矩阵-Phi-需要满足的性质" class="headerlink" title="5.3 观测矩阵$\Phi$需要满足的性质"></a>5.3 观测矩阵$\Phi$需要满足的性质</h3><p>&emsp;&emsp;1. 随机性。$\Phi$可以是高斯分布的白噪声矩阵，或伯努利分布的$\pm1$矩阵。  </p>
<p>&emsp;&emsp;2. 使线性测量有稳定的能量性质，即满足$1-\delta\leq\frac{\Vert \Phi\Psi^\mathrm{H}s\Vert _2}{\Vert s\Vert _2}\leq1+\delta$，也就是它要保持$K$个重要分量的长度。  </p>
<p>&emsp;&emsp;3. 实际运用中，对$\Phi$的维度有要求，$y$的长度一般是重要分量长度的4倍，才能近乎完美重构。即$M\approx4K$或者$M\geq Klog_2(\frac{N}{K})$。  </p>
<h3 id="5-4-如何解决4-1中提出的优化问题"><a href="#5-4-如何解决4-1中提出的优化问题" class="headerlink" title="5.4 如何解决4.1中提出的优化问题"></a>5.4 如何解决4.1中提出的优化问题</h3><p>&emsp;&emsp;对于$min\Vert y-\Phi\Psi^\mathrm{H}s\Vert _2+\lambda\Vert s\Vert _0$ 的优化，其中的0-范数优化问题是NP难问题，因此我们必须要换成1-范数进行优化，而1-范数优化是一个凸优化问题。  </p>
<h4 id="5-4-1-为什么要将0-范数转换成1-范数而非2-范数进行优化呢？"><a href="#5-4-1-为什么要将0-范数转换成1-范数而非2-范数进行优化呢？" class="headerlink" title="5.4.1 为什么要将0-范数转换成1-范数而非2-范数进行优化呢？"></a>5.4.1 为什么要将0-范数转换成1-范数而非2-范数进行优化呢？</h4><p>&emsp;&emsp;我们把问题放到二维空间来看：  </p>
<p>&emsp;&emsp;在二维空间里，假设$s$有两个分量$(s_1,s_2)$，则假设$y$为1维向量，也就是一个数。  </p>
<p>&emsp;&emsp;假设我们使用2-范数那么根据文章思路，令$T=\Phi\Psi^\mathrm{H}$，则有$y=Ts$。  </p>
<p>&emsp;&emsp;<strong>那么问题就变成了在满足等式约束$y=Ts$的情况下，求$\Vert s\Vert _2$的最小值。</strong>  </p>
<p>&emsp;&emsp;$y=Ts$是二维空间中的一个超平面，为了简化，在2-D问题中看作一条直线；而$\Vert s\Vert _2^2=s_1^2+s_2^2$，即为半径为$\Vert s\Vert _2$的圆，要求该圆半径的最小值。直线和圆的关系在二维空间中如图所示：  </p>
<p><img src="http://odnk9as2f.bkt.clouddn.com/L2.png?imageView/2/w/300/q/90" alt="二维空间中直线和圆的关系">  </p>
<p>我们将圆的半径逐渐增大，直到与$y=Ts$相切时，有$\Vert s\Vert _2^2$最小，此时圆与直线的交点坐标即为$s$的两个分量值，此时的$s$几乎不可能是稀疏的。  </p>
<p>&emsp;&emsp;因此我们考虑$\hat{y}$的1-范数，那么问题变成了在满足$y=Ts$的情况下，求$\Vert s\Vert _1$的最小值。$\Vert s\Vert _1=\vert s_1\vert +\vert s_2\vert $，该函数在二维空间中的图如下所示：  </p>
<p><img src="http://odnk9as2f.bkt.clouddn.com/L1.png?imageView/2/w/300/q/90" alt>  </p>
<p>我们将菱形边长从原点开始逐渐增大，直到与直线$y=Ts$相切位置，菱形与直线的交点即为$s$的两个分量值，此时有很大可能性该交点在坐标轴上，因此所求$s$很可能是稀疏的。  </p>
<h4 id="5-4-2-对于1-范数的优化问题，如何进行求解？——正交匹配追踪法"><a href="#5-4-2-对于1-范数的优化问题，如何进行求解？——正交匹配追踪法" class="headerlink" title="5.4.2 对于1-范数的优化问题，如何进行求解？——正交匹配追踪法"></a>5.4.2 对于1-范数的优化问题，如何进行求解？——正交匹配追踪法</h4><p>&emsp;&emsp;对于$y=Ts$,由于$s$是$K$稀疏的，我们要找其$K$个分量，这$K$个分量系数的绝对值应该比其他$N-K$个分量的系数大得多。  </p>
<p>&emsp;&emsp;我们先假设$K=1$，此时唯一非零元素$s_q$在$s$中对应的位置在$q$。则$Ts$就是恢复矩阵$T$的第$q$列$T_q$与$s$中的非零元素$s_q$的乘积，即$T_qs_q=y_q$，且$\frac{\Vert y-y_q\Vert _2}{\Vert y\Vert _2}&lt;\delta$。换句话说，$T$的第$q$列与$y$的相似程度最高，即$\vert \langle T_q,y\rangle \vert =\vert T_q^\mathrm{H}y\vert \gg \vert T_r^\mathrm{H}y\vert =\vert \langle T_r,y\rangle \vert , r\neq q$。所以，我们只要计算恢复矩阵$T$的所有列与$y$的内积，找到内积绝对值最大的那列就行了，该列对应的位置就是$q$。根据最小二乘法，$s_q=(T_q^\mathrm{H}T_q)^{-1}T_q^\mathrm{H}y$，就是使$\Vert y-T_qs_q\Vert _2$最小的那个$s_q$。此时余量$r_n=y-\frac{\langle T_q,y \rangle}{\langle T_q,T_q\rangle }T_q$，始终同$T_q$正交，很像施密特正交化方法。  </p>
<p>&emsp;&emsp;当$K=2$，则$s$有两个非零元素$s_{q1}$和$s_{q2}$，其在$s$中的位置分别为$q1$和$q2$。则$T$的第$q1$和$q2$列与$y$的相似程度最高。我们要找到使$\Vert y-(T_{q2},T_{q1})\begin{pmatrix} s_{q2}\ s_{q1} \end{pmatrix}\Vert <em>2$最小的那个$\begin{pmatrix} s</em>{q2}\ s_{q1} \end{pmatrix}$。这里$T_{q1}$是我们第一次找到的那一列，$T_{q2}$是我们要重新找的那一列。此时我们找到两个在变换域最关键的元素和其在$s$中对应的位置了。令$T_q=(T_{q2},T_{q1})$，余量$r_n$又一次被写为$r_n=y-\frac{\langle T_q,y \rangle}{\langle T_q,T_q \rangle}T_q$。  </p>
<p>&emsp;&emsp;当$K&gt;1$时，类似上面的步骤，迭代找到变换域中$K$个最重要的分量。正交匹配的迭代次数$m\geq K$，实际上操作只要满足$\frac{\Vert r_n\Vert _2}{\Vert y\Vert _2}&lt;\delta$，迭代就可以中止了。</p>
<p>  主要参考：  </p>
<ol>
<li><a href="http://blog.csdn.net/abcjennifer/article/details/7748833" target="_blank" rel="noopener">http://blog.csdn.net/abcjennifer/article/details/7748833</a>  </li>
<li>《“压缩传感”引论》.沙威.香港大学</li>
</ol>
	  
	</div>

	<!-- recommended posts -->
	

	<div>
  	<center>
	<div class="pagination">
<ul class="pagination">
	 
				
    	<li class="prev"><a href="/2017/04/29/深度学习笔记：稀疏自编码器（1）————神经元与神经网络/" class="alignleft prev"><i class="fa fa-arrow-circle-o-left"></i>上一页</a></li>
  		

        <li><a href="/archives"><i class="fa fa-archive"></i>Archive</a></li>

		
		   <li class="next"><a href="/2017/04/01/VMware虚拟CentOS-6-5在NAT模式下配置静态IP地址及Xshell远程控制配置/" class="alignright next">下一页<i class="fa fa-arrow-circle-o-right"></i></a></li>         
        
	
</ul>
</div>

    </center>
	</div>

    <!-- share -->
    
        
    <div class="bdsharebuttonbox">
        <a href="#" class="bds_more" data-cmd="more"></a>
        <a href="#" class="bds_weixin" data-cmd="weixin" title="分享到微信"></a>
        <a href="#" class="bds_tsina" data-cmd="tsina" title="分享到新浪微博"></a>
        <a href="#" class="bds_fbook" data-cmd="fbook" title="分享到Facebook"></a>
        <a href="#" class="bds_twi" data-cmd="twi" title="分享到Twitter"></a>
        <a href="#" class="bds_linkedin" data-cmd="linkedin" title="分享到linkedin"></a>
        <a href="#" class="bds_evernotecn" data-cmd="evernotecn" title="分享到印象笔记"></a>
        <a href="#" class="bds_youdao" data-cmd="youdao" title="分享到有道云笔记"></a>
        <a href="#" class="bds_copy" data-cmd="copy" title="分享到复制网址"></a>
    </div>
    <script>
        window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"2","bdMiniList":false,"bdPic":"","bdStyle":"1","bdSize":"24"},"share":{}};
        with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];
    </script>


        

    
	
	<!-- comment -->
	
<section id="comment">
  <h2 class="title">留言</h2>
    	 
	 <div id="comment-thread"></div>
	 <div id="loading-spin"></div>
	 <script type="text/javascript">
	   getComments({
           type: "github" ? "github" : "github",       
	       user: "wzpan",
	       repo: "hexo-theme-freemind-blog",
		   client_id: "bf7d4ba11877db88543e",
           client_secret: "bff8a6b06b745c0bfcdccbe225623ea8e2a057bb",
		   no_comment: "暂时还没有留言呢，点击下面的按钮去留言吧！",
		   go_to_comment: "去留言",
		   no_issue: "no_issue",
		   issue_title: "压缩感知算法原理",
		   issue_id: "undefined",
		   btn_class: "btn btn-primary",
		   comments_target: "#comment-thread",
		   loading_target: "#loading_spin"
		   });
	 </script>
  
</section>


	</div> <!-- col-md-9/col-md-12 -->
		
	
	<div id="side_meta">
		<div class="col-md-3" id="post_meta"> 

	<!-- date -->
	
	<div class="meta-widget">
	<i class="fa fa-clock-o"></i>
	2017-04-06 
	</div>
	

	<!-- categories -->
    
	<div class="meta-widget">
	<a data-toggle="collapse" data-target="#categorys"><i class="fa fa-folder"></i></a>	
    <ul id="categorys" class="tag_box list-unstyled collapse in">
          
  <li>
    <li><a href="/categories/图像处理/">图像处理<span>1</span></a></li>
  </li>

    </ul>
	</div>
	

	<!-- tags -->
	
	<div class="meta-widget">
	<a data-toggle="collapse" data-target="#tags"><i class="fa fa-tags"></i></a>		  
    <ul id="tags" class="tag_box list-unstyled collapse in">	  
	    
  <li><a href="/tags/图像处理/">图像处理<span>1</span></a></li>
    </ul>
	</div>
	

	<!-- toc -->
	<div class="meta-widget">
	
	</div>
	
    <hr>
	
</div><!-- col-md-3 -->

	</div>
		

</div><!-- row -->



    </div>
  </div>
  <div class="container-narrow">
    <footer> <p>
  &copy; 2020 Aaron Wu
  
      with help from <a href="http://hexo.io/" target="_blank">Hexo</a> and <a href="http://getbootstrap.com/" target="_blank">Twitter Bootstrap</a>. Theme by <a href="http://github.com/wzpan/hexo-theme-freemind/">Freemind</a>.    
</p> </footer>
  </div> <!-- container-narrow -->
  


  
<a id="gotop" href="#">   
  <span>▲</span> 
</a>

<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/bootstrap.min.js"></script>
<script src="/js/main.js"></script>
<script src="/js/search.js"></script> 


<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>




<!-- syntax highlighting -->

  <script>
  marked.setOptions({
    highlight: function (code, lang) {
        return hljs.highlightAuto(code).value;
    }
  });
  function Highlighting(){
    var markdowns = document.getElementsByClassName('markdown');
    for(var i=0;i<markdowns.length;i++){
        if(markdowns[i].innerHTML) markdowns[i].innerHTML =marked(markdowns[i].innerHTML);
    }
  }
  window.addEventListener('DOMContentLoaded', Highlighting, false);
  window.addEventListener('load', Highlighting, false);
  </script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->


</body>
</html>